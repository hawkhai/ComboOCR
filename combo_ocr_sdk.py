#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ComboOCR SDK - å¤–è§‚å¢å¼ºä¸æ‰­æ›²çŸ«æ­£ SDK

æä¾›ä¸¤ä¸ªæ ¸å¿ƒåŠŸèƒ½ï¼š
1. å¤–è§‚å¢å¼º (Appearance Enhancement) - å»é˜´å½±/å»å™ª
2. æ‰­æ›²çŸ«æ­£ (Distortion Correction) - æ–‡æ¡£æ‰­æ›²çŸ«æ­£

åŸºäº GCDRNet å’Œ DocTr++ æ¨¡å‹å®ç°
"""

import os
import cv2
import torch
import numpy as np
import gc
from typing import Optional, Tuple, Dict, Any
import torch.nn.functional as F

# å¯¼å…¥å¿…è¦çš„å·¥å…·å‡½æ•°å’Œæ¨¡å‹
from utils.utils_doctr_plus import DocTr_Plus
from utils.utils_gcdrnet import stride_integral, convert_state_dict
from model.unext import UNext_full_resolution_padding, UNext_full_resolution_padding_L_py_L


class ComboOCRSDK:
    """
    ComboOCR SDK ä¸»ç±»
    
    æä¾›å¤–è§‚å¢å¼ºå’Œæ‰­æ›²çŸ«æ­£åŠŸèƒ½çš„ç»Ÿä¸€æ¥å£
    """
    
    def __init__(self, device: str = "cpu"):
        """
        åˆå§‹åŒ– SDK
        
        Args:
            device: è®¡ç®—è®¾å¤‡ï¼Œæ”¯æŒ "cpu", "cuda", "cuda:0" ç­‰
        """
        self.device = torch.device(device)
        self.models = {
            'gcnet': None,      # å¤–è§‚å¢å¼ºæ¨¡å‹1 - é˜´å½±æ£€æµ‹
            'drnet': None,      # å¤–è§‚å¢å¼ºæ¨¡å‹2 - å»å™ªå¢å¼º
            'dewarp_model': None  # æ‰­æ›²çŸ«æ­£æ¨¡å‹
        }
        self._enhancement_available = False
        self._dewarp_available = False
        
    def load_enhancement_models(self, 
                              gcnet_path: str = './models/gcdr_net/gcnet/checkpoint.pkl',
                              drnet_path: str = './models/gcdr_net/drnet/checkpoint.pkl') -> bool:
        """
        åŠ è½½å¤–è§‚å¢å¼ºæ¨¡å‹
        
        Args:
            gcnet_path: GCNet æ¨¡å‹è·¯å¾„ (é˜´å½±æ£€æµ‹)
            drnet_path: DRNet æ¨¡å‹è·¯å¾„ (å»å™ªå¢å¼º)
            
        Returns:
            bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            if not os.path.exists(gcnet_path) or not os.path.exists(drnet_path):
                print(f"å¤–è§‚å¢å¼ºæ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°:")
                print(f"  GCNet: {gcnet_path} - {'å­˜åœ¨' if os.path.exists(gcnet_path) else 'ä¸å­˜åœ¨'}")
                print(f"  DRNet: {drnet_path} - {'å­˜åœ¨' if os.path.exists(drnet_path) else 'ä¸å­˜åœ¨'}")
                return False
            
            # åŠ è½½ GCNet (é˜´å½±æ£€æµ‹ç½‘ç»œ)
            self.models['gcnet'] = UNext_full_resolution_padding(
                num_classes=3, 
                input_channels=3, 
                img_size=512
            ).to(self.device)
            
            state = convert_state_dict(
                torch.load(gcnet_path, map_location=self.device)['model_state']
            )
            self.models['gcnet'].load_state_dict(state)
            self.models['gcnet'].eval()
            print("âœ… GCNet æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # åŠ è½½ DRNet (å»å™ªå¢å¼ºç½‘ç»œ)
            self.models['drnet'] = UNext_full_resolution_padding_L_py_L(
                num_classes=3, 
                input_channels=6, 
                img_size=512
            ).to(self.device)
            
            state = convert_state_dict(
                torch.load(drnet_path, map_location=self.device)['model_state']
            )
            self.models['drnet'].load_state_dict(state)
            self.models['drnet'].eval()
            print("âœ… DRNet æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            self._enhancement_available = True
            return True
            
        except Exception as e:
            print(f"âŒ å¤–è§‚å¢å¼ºæ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            self.models['gcnet'] = None
            self.models['drnet'] = None
            self._enhancement_available = False
            return False
    
    def load_dewarp_model(self, model_path: str = "./models/doctr_plus/model.pt") -> bool:
        """
        åŠ è½½æ‰­æ›²çŸ«æ­£æ¨¡å‹
        
        Args:
            model_path: DocTr++ æ¨¡å‹è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦åŠ è½½æˆåŠŸ
        """
        try:
            if not os.path.exists(model_path):
                print(f"âŒ æ‰­æ›²çŸ«æ­£æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
                return False
            
            self.models['dewarp_model'] = DocTr_Plus(weights=model_path, device=self.device)
            print("âœ… æ‰­æ›²çŸ«æ­£æ¨¡å‹åŠ è½½æˆåŠŸ")
            
            self._dewarp_available = True
            return True
            
        except Exception as e:
            print(f"âŒ æ‰­æ›²çŸ«æ­£æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            self.models['dewarp_model'] = None
            self._dewarp_available = False
            return False
    
    def load_all_models(self, 
                       gcnet_path: str = './models/gcdr_net/gcnet/checkpoint.pkl',
                       drnet_path: str = './models/gcdr_net/drnet/checkpoint.pkl',
                       dewarp_path: str = "./models/doctr_plus/model.pt") -> Dict[str, bool]:
        """
        åŠ è½½æ‰€æœ‰æ¨¡å‹
        
        Args:
            gcnet_path: GCNet æ¨¡å‹è·¯å¾„
            drnet_path: DRNet æ¨¡å‹è·¯å¾„  
            dewarp_path: DocTr++ æ¨¡å‹è·¯å¾„
            
        Returns:
            Dict[str, bool]: å„æ¨¡å‹åŠ è½½çŠ¶æ€
        """
        results = {
            'enhancement': self.load_enhancement_models(gcnet_path, drnet_path),
            'dewarp': self.load_dewarp_model(dewarp_path)
        }
        
        print(f"\nğŸ“Š æ¨¡å‹åŠ è½½æ€»ç»“:")
        print(f"  å¤–è§‚å¢å¼º: {'âœ… å¯ç”¨' if results['enhancement'] else 'âŒ ä¸å¯ç”¨'}")
        print(f"  æ‰­æ›²çŸ«æ­£: {'âœ… å¯ç”¨' if results['dewarp'] else 'âŒ ä¸å¯ç”¨'}")
        
        return results
    
    def enhance_appearance(self, image: np.ndarray) -> np.ndarray:
        """
        åº”ç”¨å¤–è§‚å¢å¼ºå¤„ç† (å»é˜´å½±/å»å™ª)
        
        Args:
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼, uint8)
            
        Returns:
            np.ndarray: å¢å¼ºåçš„å›¾åƒ
            
        Raises:
            RuntimeError: å½“æ¨¡å‹æœªåŠ è½½æ—¶
        """
        if not self._enhancement_available:
            raise RuntimeError("å¤–è§‚å¢å¼ºæ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_enhancement_models()")
        
        print("ğŸ¨ å¼€å§‹å¤–è§‚å¢å¼ºå¤„ç†...")
        
        # å›¾åƒé¢„å¤„ç† - ç¡®ä¿å°ºå¯¸æ˜¯32çš„å€æ•°
        im_org, padding_h, padding_w = stride_integral(image)
        h, w = im_org.shape[:2]
        im = im_org
        
        # é¢„å…ˆå£°æ˜å˜é‡ï¼Œä¾¿äºæ¸…ç†
        im_tensor = None
        im_org_tensor = None
        shadow = None
        model1_im = None
        pred = None
        
        try:
            with torch.no_grad():
                # åˆ›å»ºå¼ é‡å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
                im_tensor = torch.from_numpy(im.transpose(2, 0, 1) / 255).unsqueeze(0).float().to(self.device)
                im_org_tensor = torch.from_numpy(im_org.transpose(2, 0, 1) / 255).unsqueeze(0).float().to(self.device)
                
                # ç¬¬ä¸€æ­¥ï¼šé˜´å½±æ£€æµ‹ (GCNet)
                shadow = self.models['gcnet'](im_tensor)
                shadow = F.interpolate(shadow, (h, w))
                
                # ç¬¬äºŒæ­¥ï¼šå»å™ªå¢å¼º (DRNet)
                model1_im = torch.clamp(im_org_tensor / shadow, 0, 1)
                pred, _, _, _ = self.models['drnet'](torch.cat((im_org_tensor, model1_im), 1))
                
                # è½¬æ¢ä¸º numpyï¼Œç«‹å³ç§»åŠ¨åˆ° CPU
                pred_np = pred[0].permute(1, 2, 0).detach().cpu().numpy()
                pred_np = (pred_np * 255).astype(np.uint8)
                pred_np = pred_np[padding_h:, padding_w:]
                
        finally:
            # æ˜¾å¼åˆ é™¤GPUå¼ é‡
            for tensor in [im_tensor, im_org_tensor, shadow, model1_im, pred]:
                if tensor is not None:
                    del tensor
            # å¼ºåˆ¶æ¸…ç†GPUç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            # è§¦å‘åƒåœ¾å›æ”¶
            gc.collect()
        
        enhanced_image = np.clip(pred_np, 0, 255).astype(np.uint8)
        print("âœ… å¤–è§‚å¢å¼ºå¤„ç†å®Œæˆ")
        return enhanced_image
    
    def correct_distortion(self, image: np.ndarray) -> np.ndarray:
        """
        åº”ç”¨æ‰­æ›²çŸ«æ­£å¤„ç†
        
        Args:
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼, uint8)
            
        Returns:
            np.ndarray: çŸ«æ­£åçš„å›¾åƒ
            
        Raises:
            RuntimeError: å½“æ¨¡å‹æœªåŠ è½½æ—¶
        """
        if not self._dewarp_available:
            raise RuntimeError("æ‰­æ›²çŸ«æ­£æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨ load_dewarp_model()")
        
        print("ğŸ“ å¼€å§‹æ‰­æ›²çŸ«æ­£å¤„ç†...")
        
        # å›¾åƒé¢„å¤„ç†
        img_ori = image / 255.0
        h_, w_, c_ = img_ori.shape
        img_ori = cv2.resize(img_ori, (2560, 2560))
        h, w, _ = img_ori.shape
        img = cv2.resize(img_ori, (288, 288))
        img = img.transpose(2, 0, 1)
        
        # é¢„å…ˆå£°æ˜å˜é‡
        img_tensor = None
        bm = None
        
        try:
            img_tensor = torch.from_numpy(img).float().unsqueeze(0).to(self.device)
            
            with torch.no_grad():
                bm = self.models['dewarp_model'](img_tensor)
                bm_np = bm.detach().cpu().numpy()[0]  # ç«‹å³ç§»åŠ¨åˆ° CPU
                
            bm0 = bm_np[0, :, :]
            bm1 = bm_np[1, :, :]
            bm0 = cv2.blur(bm0, (3, 3))
            bm1 = cv2.blur(bm1, (3, 3))
            
            img_geo = cv2.remap(img_ori, bm0, bm1, cv2.INTER_LINEAR) * 255
            img_geo = cv2.resize(img_geo, (w_, h_))
            
        finally:
            # æ˜¾å¼åˆ é™¤GPUå¼ é‡  
            for tensor in [img_tensor, bm]:
                if tensor is not None:
                    del tensor  
            # å¼ºåˆ¶æ¸…ç†GPUç¼“å­˜
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            # è§¦å‘åƒåœ¾å›æ”¶
            gc.collect()
        
        # ç¡®ä¿å›¾åƒæ˜¯uint8ç±»å‹
        corrected_image = np.clip(img_geo, 0, 255).astype(np.uint8)
        print("âœ… æ‰­æ›²çŸ«æ­£å¤„ç†å®Œæˆ")
        return corrected_image
    
    def process_image(self, 
                     image: np.ndarray, 
                     use_enhancement: bool = False, 
                     use_dewarp: bool = False) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        ç»¼åˆå¤„ç†å›¾åƒ (å¯é€‰æ‹©å¯ç”¨å¤–è§‚å¢å¼ºå’Œæ‰­æ›²çŸ«æ­£)
        
        Args:
            image: è¾“å…¥å›¾åƒ (BGRæ ¼å¼, uint8)
            use_enhancement: æ˜¯å¦å¯ç”¨å¤–è§‚å¢å¼º
            use_dewarp: æ˜¯å¦å¯ç”¨æ‰­æ›²çŸ«æ­£
            
        Returns:
            Tuple[np.ndarray, Dict]: (å¤„ç†åçš„å›¾åƒ, å¤„ç†ä¿¡æ¯)
        """
        if image is None:
            raise ValueError("è¾“å…¥å›¾åƒä¸èƒ½ä¸ºç©º")
        
        processed_image = image.copy()
        processing_info = {
            'use_enhancement': use_enhancement,
            'use_dewarp': use_dewarp,
            'enhancement_applied': False,
            'dewarp_applied': False,
            'original_shape': image.shape,
            'final_shape': None
        }
        
        print(f"ğŸš€ å¼€å§‹å›¾åƒå¤„ç†:")
        print(f"   - å¤–è§‚å¢å¼º: {'å¯ç”¨' if use_enhancement else 'ç¦ç”¨'}")
        print(f"   - æ‰­æ›²çŸ«æ­£: {'å¯ç”¨' if use_dewarp else 'ç¦ç”¨'}")
        
        # 1. å¯é€‰ï¼šå¤–è§‚å¢å¼º
        if use_enhancement:
            if self._enhancement_available:
                processed_image = self.enhance_appearance(processed_image)
                processing_info['enhancement_applied'] = True
            else:
                print("âš ï¸  å¤–è§‚å¢å¼ºæ¨¡å‹æœªåŠ è½½ï¼Œè·³è¿‡å¤–è§‚å¢å¼ºæ­¥éª¤")
        else:
            print("â­ï¸  è·³è¿‡å¤–è§‚å¢å¼ºæ­¥éª¤")
        
        # 2. å¯é€‰ï¼šæ‰­æ›²çŸ«æ­£
        if use_dewarp:
            if self._dewarp_available:
                processed_image = self.correct_distortion(processed_image)
                processing_info['dewarp_applied'] = True
            else:
                print("âš ï¸  æ‰­æ›²çŸ«æ­£æ¨¡å‹æœªåŠ è½½ï¼Œè·³è¿‡æ‰­æ›²çŸ«æ­£æ­¥éª¤")
        else:
            print("â­ï¸  è·³è¿‡æ‰­æ›²çŸ«æ­£æ­¥éª¤")
        
        processing_info['final_shape'] = processed_image.shape
        print(f"âœ… å›¾åƒå¤„ç†å®Œæˆ! åŸå§‹å°ºå¯¸: {processing_info['original_shape'][:2]} -> æœ€ç»ˆå°ºå¯¸: {processing_info['final_shape'][:2]}")
        
        return processed_image, processing_info
    
    def process_image_file(self, 
                          input_path: str, 
                          output_path: Optional[str] = None,
                          use_enhancement: bool = False, 
                          use_dewarp: bool = False) -> Tuple[str, Dict[str, Any]]:
        """
        å¤„ç†å›¾åƒæ–‡ä»¶
        
        Args:
            input_path: è¾“å…¥å›¾åƒè·¯å¾„
            output_path: è¾“å‡ºå›¾åƒè·¯å¾„ (å¯é€‰ï¼Œé»˜è®¤ä¸ºè¾“å…¥è·¯å¾„åŠ åç¼€)
            use_enhancement: æ˜¯å¦å¯ç”¨å¤–è§‚å¢å¼º
            use_dewarp: æ˜¯å¦å¯ç”¨æ‰­æ›²çŸ«æ­£
            
        Returns:
            Tuple[str, Dict]: (è¾“å‡ºæ–‡ä»¶è·¯å¾„, å¤„ç†ä¿¡æ¯)
        """
        # è¯»å–å›¾åƒ
        image = cv2.imread(input_path)
        if image is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒæ–‡ä»¶: {input_path}")
        
        # å¤„ç†å›¾åƒ
        processed_image, processing_info = self.process_image(
            image, use_enhancement, use_dewarp
        )
        
        # ç”Ÿæˆè¾“å‡ºè·¯å¾„
        if output_path is None:
            base_name = os.path.splitext(input_path)[0]
            ext = os.path.splitext(input_path)[1]
            suffix = []
            if use_enhancement:
                suffix.append("enhanced")
            if use_dewarp:
                suffix.append("dewarped")
            suffix_str = "_" + "_".join(suffix) if suffix else "_processed"
            output_path = f"{base_name}{suffix_str}{ext}"
        
        # ä¿å­˜å›¾åƒ
        cv2.imwrite(output_path, processed_image)
        processing_info['input_path'] = input_path
        processing_info['output_path'] = output_path
        
        print(f"ğŸ’¾ å›¾åƒå·²ä¿å­˜åˆ°: {output_path}")
        return output_path, processing_info
    
    @property
    def enhancement_available(self) -> bool:
        """å¤–è§‚å¢å¼ºåŠŸèƒ½æ˜¯å¦å¯ç”¨"""
        return self._enhancement_available
    
    @property  
    def dewarp_available(self) -> bool:
        """æ‰­æ›²çŸ«æ­£åŠŸèƒ½æ˜¯å¦å¯ç”¨"""
        return self._dewarp_available
    
    def get_status(self) -> Dict[str, Any]:
        """
        è·å– SDK çŠ¶æ€ä¿¡æ¯
        
        Returns:
            Dict: çŠ¶æ€ä¿¡æ¯
        """
        return {
            'device': str(self.device),
            'enhancement_available': self._enhancement_available,
            'dewarp_available': self._dewarp_available,
            'models_loaded': {
                'gcnet': self.models['gcnet'] is not None,
                'drnet': self.models['drnet'] is not None,
                'dewarp_model': self.models['dewarp_model'] is not None
            }
        }


# ä¾¿æ·å‡½æ•°
def create_sdk(device: str = "cpu") -> ComboOCRSDK:
    """
    åˆ›å»º ComboOCR SDK å®ä¾‹çš„ä¾¿æ·å‡½æ•°
    
    Args:
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        ComboOCRSDK: SDK å®ä¾‹
    """
    return ComboOCRSDK(device=device)


def quick_enhance(image_path: str, 
                 output_path: Optional[str] = None,
                 device: str = "cpu") -> str:
    """
    å¿«é€Ÿå¤–è§‚å¢å¼ºå¤„ç†
    
    Args:
        image_path: è¾“å…¥å›¾åƒè·¯å¾„
        output_path: è¾“å‡ºå›¾åƒè·¯å¾„
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    sdk = create_sdk(device)
    sdk.load_enhancement_models()
    output_path, _ = sdk.process_image_file(
        image_path, output_path, use_enhancement=True, use_dewarp=False
    )
    return output_path


def quick_dewarp(image_path: str, 
                output_path: Optional[str] = None,
                device: str = "cpu") -> str:
    """
    å¿«é€Ÿæ‰­æ›²çŸ«æ­£å¤„ç†
    
    Args:
        image_path: è¾“å…¥å›¾åƒè·¯å¾„
        output_path: è¾“å‡ºå›¾åƒè·¯å¾„  
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    sdk = create_sdk(device)
    sdk.load_dewarp_model()
    output_path, _ = sdk.process_image_file(
        image_path, output_path, use_enhancement=False, use_dewarp=True
    )
    return output_path


def quick_process(image_path: str,
                 output_path: Optional[str] = None, 
                 use_enhancement: bool = True,
                 use_dewarp: bool = True,
                 device: str = "cpu") -> str:
    """
    å¿«é€Ÿç»¼åˆå¤„ç† (å¤–è§‚å¢å¼º + æ‰­æ›²çŸ«æ­£)
    
    Args:
        image_path: è¾“å…¥å›¾åƒè·¯å¾„
        output_path: è¾“å‡ºå›¾åƒè·¯å¾„
        use_enhancement: æ˜¯å¦å¯ç”¨å¤–è§‚å¢å¼º
        use_dewarp: æ˜¯å¦å¯ç”¨æ‰­æ›²çŸ«æ­£
        device: è®¡ç®—è®¾å¤‡
        
    Returns:
        str: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    sdk = create_sdk(device)
    sdk.load_all_models()
    output_path, _ = sdk.process_image_file(
        image_path, output_path, use_enhancement, use_dewarp
    )
    return output_path


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    print("ğŸ¯ ComboOCR SDK ç¤ºä¾‹")
    
    # åˆ›å»º SDK å®ä¾‹
    sdk = create_sdk(device="cpu")  # æˆ– "cuda" å¦‚æœæœ‰GPU
    
    # åŠ è½½æ‰€æœ‰æ¨¡å‹
    results = sdk.load_all_models()
    
    # æ£€æŸ¥çŠ¶æ€
    status = sdk.get_status()
    print(f"\nğŸ“Š SDK çŠ¶æ€: {status}")
    
    # ç¤ºä¾‹ï¼šå¤„ç†å›¾åƒæ–‡ä»¶
    # output_path = sdk.process_image_file(
    #     "input.jpg", 
    #     "output.jpg",
    #     use_enhancement=True, 
    #     use_dewarp=True
    # )
    
    print("\nğŸ“š ä½¿ç”¨è¯´æ˜:")
    print("1. åˆ›å»º SDK: sdk = create_sdk()")
    print("2. åŠ è½½æ¨¡å‹: sdk.load_all_models()")  
    print("3. å¤„ç†å›¾åƒ: sdk.process_image_file('input.jpg', use_enhancement=True, use_dewarp=True)")
    print("4. æˆ–ä½¿ç”¨ä¾¿æ·å‡½æ•°: quick_process('input.jpg')")
